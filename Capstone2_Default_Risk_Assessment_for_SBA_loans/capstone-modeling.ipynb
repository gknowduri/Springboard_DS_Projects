{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167be40c",
   "metadata": {},
   "source": [
    "## Modeling: Small business loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b3cb4",
   "metadata": {},
   "source": [
    "I will now build a model to classify small business loans according to whether they will be paid off or default. This is a classification problem, and many of the variables have skewed distributions. Decision tree algorithms often perform well in such cases. I will try two decision-tree based algorithms: random forest, and gradient boosting. I will also tune hyperparameters for both algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf36ac",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cee0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import needed Python module and functions \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b02c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import features for training values\n",
    "features = pd.read_csv('./Data/Processed/X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import labels for training data\n",
    "labels = pd.read_csv('./Data/Processed/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert training data into numpy arrays to train models\n",
    "feature_names = features.columns\n",
    "X = features.values\n",
    "y = labels.values\n",
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2251632",
   "metadata": {},
   "source": [
    "### Random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba424aeb",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c90f2b",
   "metadata": {},
   "source": [
    "To get a benchmark for hyperparameter tuning, let's first see how the Random Forest algorithm performs just using the `sklearn` defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e570a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098df602",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_rf = cross_validate(rf_model, X, y, scoring=('f1', 'accuracy'), cv=3, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061717ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time         150.317626\n",
       "score_time         8.107573\n",
       "test_f1            0.780226\n",
       "test_accuracy      0.929110\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Print out cross-validated metrics for the 'out of the box' model.\n",
    "pd.DataFrame(cv_results_rf).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224db5c",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce50cc",
   "metadata": {},
   "source": [
    "Now, let's see if I can do better with hyperparameter tuning. Since the data is unbalanced, I will use f1 score as the metric to optimize, rather than accuracy. While there are many hyperparameters I could tune, I will focus on `n_estimators`, `criterion` and `max_depth.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede3de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up grid with possible combinations of hyperparameters to search\n",
    "params = {'n_estimators': [50, 100, 200],\n",
    "          'criterion' : ['gini', 'entropy'],\n",
    "          'max_depth': [50, 100, 200, None]\n",
    "}\n",
    "\n",
    "rf_for_search = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d78006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=50, n_estimators=50; accuracy: (test=0.928) f1: (test=0.777) total time= 1.3min\n",
      "[CV 2/3] END criterion=gini, max_depth=50, n_estimators=50; accuracy: (test=0.929) f1: (test=0.778) total time= 1.4min\n",
      "[CV 3/3] END criterion=gini, max_depth=50, n_estimators=50; accuracy: (test=0.929) f1: (test=0.780) total time= 1.3min\n",
      "[CV 1/3] END criterion=gini, max_depth=50, n_estimators=100; accuracy: (test=0.928) f1: (test=0.779) total time= 2.6min\n",
      "[CV 2/3] END criterion=gini, max_depth=50, n_estimators=100; accuracy: (test=0.929) f1: (test=0.781) total time= 2.7min\n",
      "[CV 3/3] END criterion=gini, max_depth=50, n_estimators=100; accuracy: (test=0.929) f1: (test=0.781) total time= 2.7min\n",
      "[CV 1/3] END criterion=gini, max_depth=50, n_estimators=200; accuracy: (test=0.929) f1: (test=0.781) total time= 5.3min\n",
      "[CV 2/3] END criterion=gini, max_depth=50, n_estimators=200; accuracy: (test=0.930) f1: (test=0.782) total time= 5.8min\n",
      "[CV 3/3] END criterion=gini, max_depth=50, n_estimators=200; accuracy: (test=0.929) f1: (test=0.781) total time= 5.2min\n",
      "[CV 1/3] END criterion=gini, max_depth=100, n_estimators=50; accuracy: (test=0.929) f1: (test=0.781) total time= 1.3min\n",
      "[CV 2/3] END criterion=gini, max_depth=100, n_estimators=50; accuracy: (test=0.929) f1: (test=0.778) total time= 1.2min\n",
      "[CV 3/3] END criterion=gini, max_depth=100, n_estimators=50; accuracy: (test=0.928) f1: (test=0.776) total time= 1.3min\n",
      "[CV 1/3] END criterion=gini, max_depth=100, n_estimators=100; accuracy: (test=0.929) f1: (test=0.780) total time= 2.5min\n",
      "[CV 2/3] END criterion=gini, max_depth=100, n_estimators=100; accuracy: (test=0.929) f1: (test=0.781) total time= 2.4min\n",
      "[CV 3/3] END criterion=gini, max_depth=100, n_estimators=100; accuracy: (test=0.929) f1: (test=0.779) total time= 2.3min\n",
      "[CV 1/3] END criterion=gini, max_depth=100, n_estimators=200; accuracy: (test=0.929) f1: (test=0.781) total time= 4.7min\n",
      "[CV 2/3] END criterion=gini, max_depth=100, n_estimators=200; accuracy: (test=0.930) f1: (test=0.783) total time= 4.6min\n",
      "[CV 3/3] END criterion=gini, max_depth=100, n_estimators=200; accuracy: (test=0.929) f1: (test=0.780) total time= 4.8min\n",
      "[CV 1/3] END criterion=gini, max_depth=200, n_estimators=50; accuracy: (test=0.929) f1: (test=0.781) total time= 1.3min\n",
      "[CV 2/3] END criterion=gini, max_depth=200, n_estimators=50; accuracy: (test=0.929) f1: (test=0.778) total time= 1.2min\n",
      "[CV 3/3] END criterion=gini, max_depth=200, n_estimators=50; accuracy: (test=0.928) f1: (test=0.776) total time= 1.2min\n",
      "[CV 1/3] END criterion=gini, max_depth=200, n_estimators=100; accuracy: (test=0.929) f1: (test=0.780) total time= 2.4min\n",
      "[CV 2/3] END criterion=gini, max_depth=200, n_estimators=100; accuracy: (test=0.929) f1: (test=0.781) total time= 2.4min\n",
      "[CV 3/3] END criterion=gini, max_depth=200, n_estimators=100; accuracy: (test=0.929) f1: (test=0.779) total time= 2.4min\n",
      "[CV 1/3] END criterion=gini, max_depth=200, n_estimators=200; accuracy: (test=0.929) f1: (test=0.781) total time= 4.8min\n",
      "[CV 2/3] END criterion=gini, max_depth=200, n_estimators=200; accuracy: (test=0.930) f1: (test=0.783) total time= 4.9min\n",
      "[CV 3/3] END criterion=gini, max_depth=200, n_estimators=200; accuracy: (test=0.929) f1: (test=0.780) total time= 5.0min\n",
      "[CV 1/3] END criterion=gini, max_depth=None, n_estimators=50; accuracy: (test=0.929) f1: (test=0.781) total time= 1.3min\n",
      "[CV 2/3] END criterion=gini, max_depth=None, n_estimators=50; accuracy: (test=0.929) f1: (test=0.778) total time= 1.2min\n",
      "[CV 3/3] END criterion=gini, max_depth=None, n_estimators=50; accuracy: (test=0.928) f1: (test=0.776) total time= 1.2min\n",
      "[CV 1/3] END criterion=gini, max_depth=None, n_estimators=100; accuracy: (test=0.929) f1: (test=0.780) total time= 2.4min\n",
      "[CV 2/3] END criterion=gini, max_depth=None, n_estimators=100; accuracy: (test=0.929) f1: (test=0.781) total time= 2.3min\n",
      "[CV 3/3] END criterion=gini, max_depth=None, n_estimators=100; accuracy: (test=0.929) f1: (test=0.779) total time= 2.4min\n",
      "[CV 1/3] END criterion=gini, max_depth=None, n_estimators=200; accuracy: (test=0.929) f1: (test=0.781) total time= 4.7min\n",
      "[CV 2/3] END criterion=gini, max_depth=None, n_estimators=200; accuracy: (test=0.930) f1: (test=0.783) total time= 9.5min\n",
      "[CV 3/3] END criterion=gini, max_depth=None, n_estimators=200; accuracy: (test=0.929) f1: (test=0.780) total time= 5.0min\n"
     ]
    }
   ],
   "source": [
    "## Execute grid search to find the best hyperparameters\n",
    "search_results_rf = GridSearchCV(estimator=rf_for_search, param_grid=params, \n",
    "                                 cv=3, scoring=('accuracy', 'f1'), \n",
    "                                 refit='f1', n_jobs=1, verbose=5)\n",
    "search_results_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf = pd.DataFrame(search_results_rf.cv_results_)[['param_criterion', \n",
    "                                                         'param_n_estimators', \n",
    "                                                         'param_max_depth', \n",
    "                                                         'mean_test_accuracy', \n",
    "                                                         'mean_test_f1', \n",
    "                                                         'mean_fit_time']]\n",
    "scores_rf.sort_values(by='mean_test_f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print out the best hyperparameters found\n",
    "search_results_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07568c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = search_results_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3671702",
   "metadata": {},
   "source": [
    "Now that I have chosen the best hyperparameters for the random forest model, I fit the model on the entire training set, and evaluate performance on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Fit our optimized random forest model to the training data\n",
    "best_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_df = pd.read_csv('./Data/Processed/X_test.csv')\n",
    "y_val_df = pd.read_csv('./Data/Processed/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the validation data, and save features as an array and labels as a \n",
    "X_val = X_val_df.values\n",
    "y_val = y_val_df.values\n",
    "y_val = y_val.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Use our model to make a prediction on the validation set\n",
    "y_val_pred_rf = best_rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6884255",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print metrics for this model.\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_val_pred_rf, y_val)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_val_pred_rf, y_val)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_val_pred_rf, y_val)))\n",
    "print(\"f1 score: {:.2f}\".format(f1_score(y_val_pred_rf, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f0cf4",
   "metadata": {},
   "source": [
    "Finally, let's examine the most important features of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ad5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph shows feature importances for this model\n",
    "plt.subplots(figsize=(10, 5))\n",
    "importances = best_rf.feature_importances_\n",
    "labeled_importances = pd.Series(importances, index=feature_names).sort_values(ascending=False)[:10]\n",
    "labeled_importances.plot(kind='bar')\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('importance')\n",
    "plt.title('Best random forest model feature importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c243ad8",
   "metadata": {},
   "source": [
    "#### Conclusion: random forest\n",
    "\n",
    "Random forest offers decent performance even with the default hyperparameters from `sklearn`. However, my efforts to improve performance with hyperparameter turning were not very successful. The optimized model performed only about one percentage point better on the target metric, but took more than three times longer to train. It's possible that the algorithm would do better with an even larger value of `n_estimators`, but this would mean longer training times. For now, I will try a different algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe93248",
   "metadata": {},
   "source": [
    "### Gradient Boosting Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d527e1",
   "metadata": {},
   "source": [
    "#### Evaluating the default model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38aee8",
   "metadata": {},
   "source": [
    "I will now follow a similar process with gradient boosting. To being, I will evaluate the default version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9809b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_gb = cross_validate(gb_model, X, y, scoring=('f1', 'accuracy'), cv=3, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3802ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print cross-validated metrics for the 'out of the box' gradient boosting model\n",
    "pd.DataFrame(cv_results_gb).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0aa02",
   "metadata": {},
   "source": [
    "It seems that gradient boosting gives similar performance to random forest with the default setting. Lets see if gradient boosting is more responsive to hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7c74a",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a7725",
   "metadata": {},
   "source": [
    "One again I conduct a grid search. This time instead of `criterion`, I vary the parameter `learning_rate`, which determines how quickly the boosting algorithm learns from its mistakes at each iteration. Gradient boosting tends to perform well with a large number of relatively shallow trees, so I will try small values for `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee926caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameter grid and declare a new estimator\n",
    "params_gb = {'n_estimators': [100, 200],\n",
    "            'max_depth': [7, 11, 15],\n",
    "            'learning_rate': [0.01, 0.1, 1]}\n",
    "\n",
    "gb_for_search = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the grid search\n",
    "search_results_gb = GridSearchCV(estimator=gb_for_search, param_grid=params_gb, cv=3, \n",
    "                                 scoring=('accuracy', 'f1'), refit='f1', \n",
    "                                 n_jobs=1, verbose=5)\n",
    "search_results_gb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ac6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print out metrics for the top 5 models\n",
    "scores_gb = pd.DataFrame(search_results_gb.cv_results_)[['param_learning_rate', \n",
    "                                                         'param_max_depth', \n",
    "                                                         'param_n_estimators', \n",
    "                                                         'mean_test_accuracy', \n",
    "                                                         'mean_test_f1', \n",
    "                                                         'mean_fit_time']]\n",
    "scores_gb.sort_values(by='mean_test_f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5287c34",
   "metadata": {},
   "source": [
    "Here I noticed something interesting. The second-best model performs almost as well as the best model--both accuracy and precision agree to the second decimal place--but requires only about half the training time. Since gradient boosting models generally need much more training time than random forest, this is an important consideration. Using a model that is easier to train means I could more easily improve the model by training on more recent data if it became available. So, I will select the *second* model in the table above as the optimized gradient boosting classifier.\n",
    "\n",
    "I now train a model with the chosen hyperparameters from the search, and evaluate its performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose the estimator with the best f1 score\n",
    "best_gb = GradientBoostingClassifier(n_estimators=100, \n",
    "                                     learning_rate=0.1, max_depth=11, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Fit the optimized gradient boosting model to all of the training data\n",
    "best_gb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Now, use the optimized gradient boosting model to make predictions for the test set\n",
    "y_val_pred_gb = best_gb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print evaluation metrics for this model.\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_val_pred_gb, y_val)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_val_pred_gb, y_val)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_val_pred_gb, y_val)))\n",
    "print(\"f1 score: {:.2f}\".format(f1_score(y_val_pred_gb, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a101e78",
   "metadata": {},
   "source": [
    "Finally, I plot feature importances for the gradient boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(10, 5))\n",
    "importances = best_gb.feature_importances_\n",
    "labeled_importances = pd.Series(importances, index=feature_names).sort_values(ascending=False)[:10]\n",
    "labeled_importances.plot(kind='bar')\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('importance')\n",
    "plt.title('Best gradient boosting model feature importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fa44a",
   "metadata": {},
   "source": [
    "#### Conclusion: gradient boosting\n",
    "\n",
    "The gradient boosting model performed similarly to random forest without hyperparameter turning. After tuning hyperparameters, I found that gradient boosting was significantly more powerful. I was able to acheive an f1 score of 0.85, a full 6 percentage-points higher than my best random forest model. The main downside was a noticeably longer training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05442e",
   "metadata": {},
   "source": [
    "### Choosing the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b587592",
   "metadata": {},
   "source": [
    "The best model is gradient boosting, with the `max_depth` parameter set to 11. (All other parameter values are defaults). This model outperformed my best random forest model on four metrics: accuracy, precision, recall, and f1-score. The most notable difference was in precision, which was 0.83 for gradient boosting verus 0.73 for random forest. Hence the gradient boosting model had fewer false positives; it is much less likely to falsely predict that a loan would go into default. \n",
    "\n",
    "The major disadvantage of gradient boosting is a longer fit time. My best gradient boosting model had a mean fit time of 750 seconds when doing three-fold cross-validation on the training data. For random forest, the mean fit time was about 200 seconds. While this is a noticable difference, the training time for gradient boosting is not prohibitive. In addition, the gradient boosting model had much faster prediction times (approximately 2 seconds to predict the test set, compared to 22 seconds for random forest). With its faster, more precise predictions, gradient boosting is worth the extra training time.\n",
    "\n",
    "As a final remark, it is reassuring to note that random forest and gradient boosting had the same top-five features, although gradient boosting put even more emphasis on the `term` feature than random forest. The fact that the models agreed on which features are import suggests that both are finding genuine relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c939774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
